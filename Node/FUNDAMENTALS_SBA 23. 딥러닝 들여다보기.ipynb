{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다층 퍼셉트론 Numpy로 직접 구현해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1. Tensorflow 기반 분류 모델 예시코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 50)                39250     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 39,760\n",
      "Trainable params: 39,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4928 - accuracy: 0.8842\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2303 - accuracy: 0.9349\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1818 - accuracy: 0.9480\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1525 - accuracy: 0.9562\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1315 - accuracy: 0.9624\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1157 - accuracy: 0.9668\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1030 - accuracy: 0.9705\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0927 - accuracy: 0.9736\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0843 - accuracy: 0.9763\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0766 - accuracy: 0.9783\n",
      "313/313 - 0s - loss: 0.1030 - accuracy: 0.9681\n",
      "test_loss: 0.10298164188861847 \n",
      "test_accuracy: 0.9681000113487244\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data set\n",
    "mnist = keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Preprocessing\n",
    "x_train_norm, x_test_norm = x_train / 255.0, x_test / 255.0\n",
    "x_train_reshaped = x_train_norm.reshape(-1, x_train_norm.shape[1]*x_train_norm.shape[2])\n",
    "x_test_reshaped = x_test_norm.reshape(-1, x_test_norm.shape[1]*x_test_norm.shape[2])\n",
    "\n",
    "# Model\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(50, activation = 'sigmoid', input_shape = (784,))) # 입력층 d = 784, 은닉층 레이어 H = 50\n",
    "model.add(keras.layers.Dense(10, activation = 'softmax')) # 출력층 레이어 K =10\n",
    "model.summary()\n",
    "\n",
    "# Model fit\n",
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "model.fit(x_train_reshaped, y_train, epochs = 10)\n",
    "\n",
    "# Model result\n",
    "test_loss, test_accuracy = model.evaluate(x_test_reshaped, y_test, verbose = 2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parameters/Weights\n",
    "\n",
    "* 입력층-은닉층, 은닉층-출력층 사이에는 사실 각각 행렬(Matrix)이 존재합니다. 예를 들어 입력값이 100개, 은닉 노드가 20개라면 사실 이 입력층-은닉층 사이에는 100x20의 형태를 가진 행렬이 존재합니다. 똑같이, MNIST 데이터처럼 10개의 클래스를 맞추는 문제를 풀기 위해 출력층이 10개의 노드를 가진다면 은닉층-출력층 사이에는 20x10의 형태를 가진 행렬이 존재하게 됩니다.\n",
    "\n",
    "* Parameter 혹은 Weight라고 부릅니다. 두 단어는 보통 같은 뜻으로 사용되지만, 실제로 Paraemter에는 위의 참고자료에서 다룬 bias 노드도 포함된다는 점만 유의해 주세요. 이때 인접한 레이어 사이에는 아래와 같은 관계가 성립합니다.\n",
    "  * y = W * X + b "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  MLP 기반 딥러닝 모델을 Numpy로 구현해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) 입력층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(5, 784)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 입력층의 데이터 형태 (shape)\n",
    "print(x_train_reshaped.shape)\n",
    "\n",
    "X = x_train_reshaped[:5]\n",
    "print(X.shape)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) Feed Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 50)\n",
      "(50,)\n",
      "(5, 50)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.03024002,  0.18070844,  0.43680751,  0.86425424, -0.20092425,\n",
       "       -1.08297497,  1.09039642,  2.36038041,  0.61050101,  0.09308163,\n",
       "        1.12573289, -0.14380748, -1.73868528,  3.02237108, -1.66558227,\n",
       "        0.85371768, -0.31168309,  1.02083372,  0.15579107, -0.47665092,\n",
       "       -0.30774701,  0.16112402,  1.01637753, -1.0007856 ,  0.49012016,\n",
       "       -0.38406476,  1.10403244, -0.11188832,  0.53628667,  0.87356289,\n",
       "       -0.14569885,  1.35171352, -0.91896555,  0.59229598,  1.27836548,\n",
       "       -0.48825673, -0.13377823,  1.23492137, -0.97049196,  0.01543511,\n",
       "       -1.48667794, -0.92618978,  0.274303  , -0.47628532,  0.16873036,\n",
       "       -0.5731898 , -0.60468755, -1.18770294,  0.77651443,  1.65543419])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_init_std = 0.1\n",
    "input_size = 784\n",
    "hidden_size = 50\n",
    "\n",
    "# 인접 레이어간 관계를 나타내는 파라미터 W를 생성하고 random 초기화\n",
    "W1 = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "\n",
    "# 바이어스 파라미터 b를 생성하고 Zero로 초기화\n",
    "b1 = np.zeros(hidden_size)\n",
    "\n",
    "a1 = np.dot(X, W1) +b1 # 은닉층 출력\n",
    "\n",
    "\n",
    "print(W1.shape)\n",
    "print(b1.shape)\n",
    "print(a1.shape)\n",
    "a1[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2-1) Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.50755943 0.54505457 0.60749806 0.70354872 0.44993725 0.25294344\n",
      " 0.74845636 0.91375579 0.64805508 0.52325362 0.75505056 0.46410996\n",
      " 0.14948    0.95357461 0.15901407 0.70134643 0.42270397 0.73513497\n",
      " 0.53886918 0.38304327 0.42366476 0.54019409 0.73426639 0.26878699\n",
      " 0.62013474 0.4051469  0.7510149  0.47205706 0.63094818 0.70548652\n",
      " 0.46363959 0.79440963 0.28516872 0.64389178 0.78217142 0.38030432\n",
      " 0.46660523 0.77467877 0.27478245 0.5038587  0.18442087 0.28369836\n",
      " 0.56814898 0.38312968 0.54208279 0.36050112 0.35327199 0.23367001\n",
      " 0.68492841 0.83962414]\n"
     ]
    }
   ],
   "source": [
    "# 첫번째 은닉층의 출력 a1에 sigmoid 적용\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "z1 = sigmoid(a1)\n",
    "print(z1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                39250     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 39,760\n",
      "Trainable params: 39,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4987 - accuracy: 0.8832\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2300 - accuracy: 0.9353\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1787 - accuracy: 0.9488\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1493 - accuracy: 0.9572\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1278 - accuracy: 0.9640\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1120 - accuracy: 0.9680\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1000 - accuracy: 0.9711\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0899 - accuracy: 0.9742\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0817 - accuracy: 0.9773\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0752 - accuracy: 0.9795\n",
      "313/313 - 0s - loss: 0.0977 - accuracy: 0.9692\n",
      "test_loss: 0.09767191857099533 \n",
      "test_accuracy: 0.9692000150680542\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# MNIST 데이터를 로드. 다운로드하지 않았다면 다운로드까지 자동으로 진행됩니다. \n",
    "mnist = keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()   \n",
    "\n",
    "# 모델에 맞게 데이터 가공\n",
    "x_train_norm, x_test_norm = x_train / 255.0, x_test / 255.0\n",
    "x_train_reshaped = x_train_norm.reshape(-1, x_train_norm.shape[1]*x_train_norm.shape[2])\n",
    "x_test_reshaped = x_test_norm.reshape(-1, x_test_norm.shape[1]*x_test_norm.shape[2])\n",
    "\n",
    "# 딥러닝 모델 구성 - 2 Layer Perceptron\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(50, activation='sigmoid', input_shape=(784,)))  # 입력층 d=784, 은닉층 레이어 H=50\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))   # 출력층 레이어 K=10\n",
    "model.summary()\n",
    "\n",
    "# 모델 구성과 학습\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(x_train_reshaped, y_train, epochs=10)\n",
    "\n",
    "# 모델 테스트 결과\n",
    "test_loss, test_accuracy = model.evaluate(x_test_reshaped,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(5, 784)\n"
     ]
    }
   ],
   "source": [
    "# 입력층 데이터의 모양(shape)\n",
    "print(x_train_reshaped.shape)\n",
    "\n",
    "# 테스트를 위해 x_train_reshaped의 앞 5개의 데이터를 가져온다.\n",
    "X = x_train_reshaped[:5]\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 50)\n",
      "(50,)\n",
      "(5, 50)\n"
     ]
    }
   ],
   "source": [
    "weight_init_std = 0.1\n",
    "input_size = 784\n",
    "hidden_size=50\n",
    "\n",
    "# 인접 레이어간 관계를 나타내는 파라미터 W를 생성하고 random 초기화\n",
    "W1 = weight_init_std * np.random.randn(input_size, hidden_size)  \n",
    "# 바이어스 파라미터 b를 생성하고 Zero로 초기화\n",
    "b1 = np.zeros(hidden_size)\n",
    "\n",
    "a1 = np.dot(X, W1) + b1   # 은닉층 출력\n",
    "\n",
    "print(W1.shape)\n",
    "print(b1.shape)\n",
    "print(a1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.26900943, -0.74499413,  0.76569976,  1.52396907,  0.77407353,\n",
       "        0.5106225 ,  0.09994509,  0.19317798,  0.49943508,  0.69454337,\n",
       "       -0.2193685 ,  0.2404075 ,  0.30131396,  0.26771715,  0.88435629,\n",
       "        0.67215659, -0.0294649 ,  0.00544126, -0.04665228,  0.81957332,\n",
       "        1.0683334 ,  1.47917226, -0.37593638,  0.96372063,  0.96274987,\n",
       "       -0.834748  , -0.13030156, -0.13883221,  0.08527631, -0.15032689,\n",
       "       -0.13430864,  0.50450818, -0.64520428, -1.549126  ,  0.0989828 ,\n",
       "       -0.79408716,  2.55269759,  1.40927037,  1.021984  , -0.24234614,\n",
       "       -1.22118648,  0.40248027, -0.68045444, -0.28597097,  0.31430273,\n",
       "        0.92634547,  0.69817375,  0.94473074, -0.57103992,  0.47605183])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫번째 데이터의 은닉층 출력을 확인해 봅시다.  50dim의 벡터가 나오나요?\n",
    "a1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5668497  0.32191303 0.68258993 0.8211222  0.68440142 0.62495239\n",
      " 0.52496549 0.54814487 0.62232656 0.66697686 0.44537675 0.55981407\n",
      " 0.57476369 0.56653238 0.70772414 0.66198589 0.49263431 0.50136031\n",
      " 0.48833904 0.69414576 0.74427984 0.81444752 0.40710737 0.72386612\n",
      " 0.72367204 0.30264207 0.46747062 0.46534759 0.52130617 0.46248889\n",
      " 0.46647322 0.62351818 0.34407105 0.17521254 0.52472551 0.31129175\n",
      " 0.92775453 0.80365084 0.73535888 0.43970826 0.22772772 0.59928343\n",
      " 0.33615988 0.42899052 0.57793516 0.71633327 0.66778274 0.72005425\n",
      " 0.3609969  0.61681514]\n"
     ]
    }
   ],
   "source": [
    "# sigmoid 함수 구현\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "z1 = sigmoid(a1)\n",
    "print(z1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단일 레이어 구현 함수\n",
    "\n",
    "def affine_layer_forward(X,W,b):\n",
    "    y = np.dot(X,W) + b\n",
    "    cache = (X,W,b)\n",
    "    return y, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.07734357  0.02036746  0.03429832 -0.09785393 -0.33464087  0.37359658\n",
      "  0.48617341  0.1699204   0.08121021 -0.68471173]\n"
     ]
    }
   ],
   "source": [
    "input_size = 784\n",
    "hidden_size = 50\n",
    "output_size = 10\n",
    "\n",
    "W1 = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "b1 = np.zeros(hidden_size)\n",
    "W2 = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "b2 = np.zeros(output_size)\n",
    "\n",
    "a1, cache1 = affine_layer_forward(X, W1, b1)\n",
    "z1 = sigmoid(a1)\n",
    "a2, cache2 = affine_layer_forward(z1, W2, b2)    # z1이 다시 두번째 레이어의 입력이 됩니다. \n",
    "\n",
    "print(a2[0])  # 최종 출력이 output_size만큼의 벡터가 되었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    if x.ndim == 2:\n",
    "        x = x.T\n",
    "        x = x - np.max(x, axis=0)\n",
    "        y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "        return y.T \n",
    "\n",
    "    x = x - np.max(x) # 오버플로 대책\n",
    "    return np.exp(x) / np.sum(np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08851644, 0.09760214, 0.09897133, 0.08671943, 0.06843546,\n",
       "       0.13895199, 0.15550927, 0.11334682, 0.10372489, 0.04822223])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = softmax(a2)\n",
    "y_hat[0]  # 10개의 숫자 중 하나일 확률이 되었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정답 라벨을 One-hot 인코딩하는 함수\n",
    "def _change_ont_hot_label(X, num_category):\n",
    "    T = np.zeros((X.size, num_category))\n",
    "    for idx, row in enumerate(T):\n",
    "        row[X[idx]] = 1\n",
    "        \n",
    "    return T\n",
    "\n",
    "Y_digit = y_train[:5]\n",
    "t = _change_ont_hot_label(Y_digit, 10)\n",
    "t     # 정답 라벨의 One-hot 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08851644 0.09760214 0.09897133 0.08671943 0.06843546 0.13895199\n",
      " 0.15550927 0.11334682 0.10372489 0.04822223]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_hat[0])\n",
    "print(t[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4199465184469715"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    # 훈련 데이터가 원-핫 벡터라면 정답 레이블의 인덱스로 반환\n",
    "    if t.size == y.size:\n",
    "        t = t.argmax(axis=1)\n",
    "             \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t])) / batch_size\n",
    "\n",
    "Loss = cross_entropy_error(y_hat, t)\n",
    "Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01770329,  0.01952043,  0.01979427,  0.01734389,  0.01368709,\n",
       "        -0.1722096 ,  0.03110185,  0.02266936,  0.02074498,  0.00964445],\n",
       "       [-0.18351893,  0.01901633,  0.01621143,  0.01469751,  0.01483514,\n",
       "         0.02658811,  0.03665958,  0.02123464,  0.0212283 ,  0.01304789],\n",
       "       [ 0.01973813,  0.01816138,  0.01960985,  0.01663035, -0.1853926 ,\n",
       "         0.0283451 ,  0.03105554,  0.02230375,  0.01859942,  0.01094909],\n",
       "       [ 0.01306896, -0.17956437,  0.01962564,  0.01974692,  0.01393162,\n",
       "         0.02832278,  0.02939372,  0.02172824,  0.02189062,  0.01185586],\n",
       "       [ 0.01312517,  0.01865193,  0.01970109,  0.01827955,  0.01593988,\n",
       "         0.0263097 ,  0.03234102,  0.02019484,  0.02244129, -0.18698447]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_num = y_hat.shape[0]\n",
    "dy = (y_hat - t) / batch_num\n",
    "dy    # softmax값의 출력으로 Loss를 미분한 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.08960477, -0.05408093,  0.0529602 ,  0.04836863, -0.06908652,\n",
       "        -0.02187472,  0.09086445,  0.06065396,  0.0589838 , -0.07718409],\n",
       "       [-0.09960359, -0.09009493,  0.06192372,  0.05701928, -0.01770513,\n",
       "        -0.07549234,  0.1055538 ,  0.07088424,  0.06955594, -0.08204098],\n",
       "       [-0.07054283, -0.06388465,  0.06342962,  0.05770504, -0.08669214,\n",
       "        -0.07640982,  0.10664529,  0.07241279,  0.06963729, -0.07230059],\n",
       "       [-0.00370311, -0.0480881 ,  0.02342693,  0.02173891, -0.04112274,\n",
       "         0.02448275,  0.03816521,  0.02585368,  0.02564127, -0.0663948 ],\n",
       "       [-0.00432232, -0.06806661,  0.04547689,  0.04130017, -0.12399126,\n",
       "        -0.02342553,  0.07371025,  0.05131757,  0.04838205, -0.04038122],\n",
       "       [-0.02853415, -0.03694057,  0.0300887 ,  0.02746236, -0.05062225,\n",
       "        -0.01577773,  0.05032331,  0.03414255,  0.03295264, -0.04309487],\n",
       "       [-0.09338662, -0.03827291,  0.05696451,  0.05170948, -0.05853396,\n",
       "        -0.08111507,  0.09759104,  0.06553326,  0.06324167, -0.06373139],\n",
       "       [-0.0770746 ,  0.00228739,  0.0442292 ,  0.03962462, -0.10518318,\n",
       "        -0.02246381,  0.07646339,  0.05093829,  0.04849756, -0.05731886],\n",
       "       [-0.02364921, -0.00911669,  0.02944639,  0.02654178, -0.08737812,\n",
       "         0.01760477,  0.04945872,  0.03312797,  0.03184528, -0.06788088],\n",
       "       [-0.03394661, -0.04383108,  0.03940106,  0.03586069, -0.03314033,\n",
       "        -0.08663743,  0.06553358,  0.04501559,  0.04315342, -0.03140889],\n",
       "       [-0.00254277, -0.04768491,  0.04554379,  0.04158036, -0.09466655,\n",
       "         0.00465122,  0.0743014 ,  0.05048341,  0.04925245, -0.12091839],\n",
       "       [-0.03894368, -0.06182905,  0.04268151,  0.0393028 , -0.00484754,\n",
       "        -0.07345619,  0.07113908,  0.04831133,  0.04748354, -0.06984182],\n",
       "       [-0.06688627, -0.08238715,  0.04395076,  0.04076348, -0.02197424,\n",
       "        -0.01061408,  0.07467313,  0.04994598,  0.04946998, -0.07694159],\n",
       "       [-0.07213049, -0.06453476,  0.06257801,  0.05718313, -0.09282475,\n",
       "        -0.01546871,  0.10564349,  0.07085684,  0.06911371, -0.12041646],\n",
       "       [-0.09504314, -0.04114578,  0.04886623,  0.04444119, -0.06038887,\n",
       "        -0.04472584,  0.08446878,  0.05645986,  0.05446563, -0.04739807],\n",
       "       [-0.09927889, -0.06199352,  0.05422427,  0.04947696, -0.07618063,\n",
       "        -0.0304761 ,  0.09325597,  0.06250395,  0.06031239, -0.05184439],\n",
       "       [-0.04412699, -0.06441212,  0.05995946,  0.05471784, -0.07929337,\n",
       "        -0.05715022,  0.09969621,  0.06771621,  0.06568468, -0.1027917 ],\n",
       "       [-0.02429034, -0.08721103,  0.03671162,  0.03411985, -0.04857064,\n",
       "         0.01258916,  0.06049806,  0.04119277,  0.04047822, -0.06551767],\n",
       "       [-0.08132294, -0.06067858,  0.06438324,  0.05864511, -0.09344828,\n",
       "        -0.04482519,  0.10897612,  0.07336214,  0.07100852, -0.09610013],\n",
       "       [-0.07360827, -0.06720437,  0.056977  ,  0.05209566, -0.08951169,\n",
       "        -0.01035216,  0.09647594,  0.06478959,  0.06295908, -0.09262077],\n",
       "       [-0.0188635 , -0.02662411,  0.03623438,  0.03258777, -0.12158003,\n",
       "         0.00194147,  0.05994405,  0.04105284,  0.03858563, -0.04327848],\n",
       "       [-0.12111594, -0.05457488,  0.06271769,  0.0574049 , -0.0312958 ,\n",
       "        -0.06017245,  0.10850994,  0.07194307,  0.07070579, -0.10412231],\n",
       "       [-0.03040179, -0.09099437,  0.0426479 ,  0.03960777, -0.03683179,\n",
       "        -0.00509337,  0.07050236,  0.0478352 ,  0.04726492, -0.08453682],\n",
       "       [-0.00024357, -0.03457714,  0.0246635 ,  0.02257307, -0.04892474,\n",
       "        -0.00395673,  0.04002508,  0.02743486,  0.02662366, -0.05361798],\n",
       "       [-0.06239096, -0.04536403,  0.04343476,  0.03968911, -0.04720167,\n",
       "        -0.03428787,  0.07388032,  0.04957373,  0.04825192, -0.06558531],\n",
       "       [-0.06122584, -0.04462329,  0.06543867,  0.05942716, -0.10031166,\n",
       "        -0.05415822,  0.10983609,  0.07407449,  0.07174486, -0.12020225],\n",
       "       [-0.00387789, -0.01139425,  0.03428756,  0.03087157, -0.06777701,\n",
       "        -0.04891896,  0.05609521,  0.0384643 ,  0.03677712, -0.06452764],\n",
       "       [-0.01758268, -0.06544541,  0.03840987,  0.03531143, -0.04028563,\n",
       "        -0.0428165 ,  0.06297779,  0.04326815,  0.04201364, -0.05585065],\n",
       "       [-0.07742751, -0.05703201,  0.04642422,  0.04252338, -0.03757464,\n",
       "        -0.04574947,  0.07939176,  0.05327699,  0.0518583 , -0.05569103],\n",
       "       [-0.08069788, -0.06333392,  0.0423045 ,  0.0386259 , -0.05765963,\n",
       "        -0.04341889,  0.07260075,  0.04918786,  0.04692948, -0.00453818],\n",
       "       [-0.07541071, -0.00977607,  0.05331567,  0.0479924 , -0.08606523,\n",
       "        -0.07133106,  0.09099939,  0.06114578,  0.058554  , -0.06942417],\n",
       "       [-0.10198987, -0.05410514,  0.05544035,  0.05061243, -0.03343937,\n",
       "        -0.08100221,  0.09538978,  0.06393361,  0.0620753 , -0.05691489],\n",
       "       [-0.03194134, -0.01144001,  0.02778695,  0.02497295, -0.0676598 ,\n",
       "        -0.02180576,  0.04695828,  0.03182006,  0.03011759, -0.02880894],\n",
       "       [-0.03173596, -0.02674815,  0.03277132,  0.02962087, -0.09061243,\n",
       "         0.00189343,  0.05500675,  0.03727679,  0.03544759, -0.04292023],\n",
       "       [-0.08739916, -0.01146086,  0.03814272,  0.03450326, -0.08180216,\n",
       "         0.01907313,  0.0670825 ,  0.04396402,  0.04257312, -0.06467657],\n",
       "       [-0.06702808, -0.03257116,  0.04550435,  0.04116277, -0.0723345 ,\n",
       "        -0.05905897,  0.07747291,  0.05241352,  0.04999326, -0.03555409],\n",
       "       [-0.03374552, -0.02429903,  0.03696406,  0.03342599, -0.08499585,\n",
       "        -0.01338972,  0.06200057,  0.04193688,  0.04014813, -0.0580455 ],\n",
       "       [-0.01748536, -0.09807725,  0.03690737,  0.03417524, -0.02393912,\n",
       "        -0.06966695,  0.05993399,  0.04205566,  0.04032366, -0.00422723],\n",
       "       [-0.03559674, -0.08964555,  0.05211233,  0.04813157, -0.02576001,\n",
       "        -0.05623764,  0.08616007,  0.05863049,  0.05770361, -0.09549813],\n",
       "       [-0.08301067, -0.08624833,  0.05925844,  0.05462534, -0.04351694,\n",
       "        -0.0233448 ,  0.10055998,  0.06724202,  0.06632701, -0.11189206],\n",
       "       [-0.00609838, -0.05894046,  0.02524142,  0.02304528, -0.09290717,\n",
       "         0.01751795,  0.04088236,  0.02865229,  0.0266798 , -0.00407308],\n",
       "       [-0.04144845, -0.01712272,  0.03358636,  0.0305666 , -0.015385  ,\n",
       "        -0.05869115,  0.05693235,  0.03817093,  0.03736711, -0.06397602],\n",
       "       [-0.07925646, -0.04177337,  0.04996276,  0.04546549, -0.07500099,\n",
       "        -0.02568664,  0.08551462,  0.05719667,  0.05537149, -0.07179358],\n",
       "       [ 0.00799412, -0.08079871,  0.06582894,  0.05979651, -0.1266848 ,\n",
       "        -0.09154147,  0.10609285,  0.0738817 ,  0.07034563, -0.08491478],\n",
       "       [-0.10734485, -0.07275701,  0.07336493,  0.06701807, -0.07365312,\n",
       "        -0.06472819,  0.12493002,  0.08376295,  0.08158958, -0.11218237],\n",
       "       [-0.0828467 , -0.03355538,  0.05026539,  0.04595822, -0.04323433,\n",
       "        -0.01907804,  0.08648066,  0.05708343,  0.05641329, -0.11748655],\n",
       "       [-0.013439  , -0.05460927,  0.03150581,  0.02886286, -0.0668258 ,\n",
       "        -0.0042044 ,  0.05164066,  0.0354913 ,  0.03409577, -0.04251792],\n",
       "       [-0.01834484, -0.04269932,  0.05997115,  0.05411199, -0.13259993,\n",
       "        -0.07162397,  0.09840736,  0.06773696,  0.06429705, -0.07925645],\n",
       "       [-0.02599018, -0.03495183,  0.05415792,  0.04900305, -0.08627874,\n",
       "        -0.0810606 ,  0.0894401 ,  0.06117719,  0.05867168, -0.08416859],\n",
       "       [-0.07340142, -0.0751492 ,  0.0623159 ,  0.05677989, -0.10574246,\n",
       "        -0.04312886,  0.10491105,  0.0711893 ,  0.06834191, -0.0661161 ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dW2 = np.dot(z1.T, dy)    \n",
    "dW2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dW2 = np.dot(z1.T, dy)\n",
    "db2 = np.sum(dy, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_grad(x):\n",
    "    return (1.0 - sigmoid(x)) * sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dz1 = np.dot(dy, W2.T)\n",
    "da1 = sigmoid_grad(a1) * dz1\n",
    "dW1 = np.dot(X.T, da1)\n",
    "db1 = np.sum(dz1, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "\n",
    "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate):\n",
    "    W1 = W1 - learning_rate*dW1\n",
    "    b1 = b1 - learning_rate*db1\n",
    "    W2 = W2 - learning_rate*dW2\n",
    "    b2 = b2 - learning_rate*db2\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
