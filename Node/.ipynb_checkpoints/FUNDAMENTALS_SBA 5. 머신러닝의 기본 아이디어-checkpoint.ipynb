{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNDAMENTALS_SBA 5. 머신러닝의 기본 아이디어"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1일 1복습하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  머신러닝이란?\n",
    "\n",
    "\n",
    "기계 학습 또는 머신 러닝은 인공 지능의 한 분야로서, 데이터를 평가하고 처리하는 과정에서 쌓인 경험을 통해 기계가 과업 처리 성능을 자동 개선하도록 하는 컴퓨터 알고리즘 연구 분야이다.\n",
    "\n",
    "\n",
    "##### 일반적인 프로그래밍과 머신러닝의 차이점?\n",
    "[Machine Learning Zero to Hero (Google I/O'19)](https://www.youtube.com/watch?v=VwVg9jCtqaU&feature=emb_title)\n",
    "\n",
    "전통적인 방법은 입력 데이터와 정답을 위한 규칙들을 프로그래밍하는 작업이었다면,\n",
    "머신러닝은 입력 데이터에 대한 정답을 알려주면 그 데이터들 사이에서 규칙을 찾는 것으로 설명하고 있습니다.\n",
    "\n",
    "\n",
    "##### 머신러닝 Workflow\n",
    "[머신 러닝의 7가지 단계 (AI 어드벤쳐)](https://www.youtube.com/watch?v=nKW8Ndu7Mjw&feature=emb_title)\n",
    "\n",
    "1. Gathering Data\n",
    "2. Preparing that Data\n",
    "3. Choosing a Model\n",
    "4. Training\n",
    "5. Evaluation\n",
    "6. Hyperparameter Tuning\n",
    "7. Prediction\n",
    "\n",
    "\n",
    "##### 좁은 의미에서, 머신러닝은 입력 데이터와 정답 데이터를 통해 가중치와 Bias를 찾는 작업"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 미분과 머신러닝\n",
    "\n",
    "머신러닝에서 미분은 시스템에서 입력 대비 출력의 관계를 내포하고, 입력이 (미세하게) 변할 때 출력이 얼마나 변하는지를 나타내고 있습니다.\n",
    "\n",
    "##### 어떤 함수 f를 x=var에서 미분한 미분계수 $$f'(var)를 구하는 코드\n",
    "\n",
    "```\n",
    "def derivative(f, var):\n",
    "    h = 1e-5\n",
    "    der = (f(var+h) - f(var-h)) / (2*h)\n",
    "    return der  \n",
    "```\n",
    "\n",
    "##### 미분 도함수를 이용해 다음 함수를 미분한 미분계수 값을 출력\n",
    "\n",
    "```\n",
    "def func(x):\n",
    "    return x**2\n",
    "\n",
    "derfunc = derivative(func, 3)\n",
    "\n",
    "derfunc\n",
    "```\n",
    "\n",
    "##### 미분을 이용해서 가중치와 Bias를 어떻게 구할까?\n",
    "\n",
    "* 1단계. 가중치 파라미터가 랜덤하게 초기화된 시작점에서 출발합니다.\n",
    "\n",
    "* 2단계. 시작점에서의 기울기를 미분을 통해 구해 봅니다. 음의 기울기가 얻어졌습니다. 이것은 가중치를 증가시키면 손실함수가 낮아진다는 뜻입니다.\n",
    "\n",
    "* 3단계. 가중치를 양의 방향, 즉 손실함수가 줄어드는 방향으로 한 스텝씩 이동합니다. 이 이동하는 보폭의 크기를 학습률(learning rate)라고 합니다.\n",
    "\n",
    "* 4단계. 손실함수가 거의 줄어들지 않는 지점까지 계속 조금씩 가중치를 이동해 봅니다. 가중치를 이동하는 방향은 현재 위치에서의 기울기 부호와 반대방향입니다.\n",
    "\n",
    "손실함수의 기울기, 미분값이 0, 최소가 되는 지점에서의 W, b를 찾으면 오차가 최소가 될 것입니다. 이러한 원리로 학습하는 것을 경사 하강법이라고 합니다.\n",
    "\n",
    "[Machine Learning week 1: Cost Function, Gradient Descent and Univariate Linear Regression](https://medium.com/@lachlanmiller_52885/machine-learning-week-1-cost-function-gradient-descent-and-univariate-linear-regression-8f5fe69815fd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
