{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPLORATION_SBA 4.  뉴스기사 크롤링 및 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "네이버 뉴스 크롤링해서, 뉴스 분야 예측하기\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library (step.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.display.max_rows=150\n",
    "%matplotlib inline\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# NLP\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "# crawling\n",
    "from konlpy.tag import Mecab\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crawling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newspaper import Article\n",
    "\n",
    "#- 파싱할 뉴스 기사 주소입니다.\n",
    "url = 'https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=101&oid=030&aid=0002881076'\n",
    "\n",
    "#- 언어가 한국어이므로 language='ko'로 설정해줍니다.\n",
    "article = Article(url, language='ko')\n",
    "article.download()\n",
    "article.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤러를 만들기 전 필요한 도구들을 임포트합니다.\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 페이지 수, 카테고리, 날짜를 입력값으로 받습니다.\n",
    "def make_urllist(page_num, code, date): \n",
    "    urllist= []\n",
    "    for i in range(1, page_num + 1):\n",
    "        url = 'https://news.naver.com/main/list.nhn?mode=LSD&mid=sec&sid1='+str(code)+'&date='+str(date)+'&page='+str(i)\n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.90 Safari/537.36'}\n",
    "        news = requests.get(url, headers=headers)\n",
    "\n",
    "        # BeautifulSoup의 인스턴스 생성합니다. 파서는 html.parser를 사용합니다.\n",
    "        soup = BeautifulSoup(news.content, 'html.parser')\n",
    "\n",
    "        # CASE 1\n",
    "        news_list = soup.select('.newsflash_body .type06_headline li dl')\n",
    "        # CASE 2\n",
    "        news_list.extend(soup.select('.newsflash_body .type06 li dl'))\n",
    "        \n",
    "    # 각 뉴스로부터 a 태그인 <a href ='주소'> 에서 '주소'만을 가져옵니다.\n",
    "    for line in news_list:\n",
    "        urllist.append(line.a.get('href'))\n",
    "    return urllist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newspaper import Article\n",
    "\n",
    "#- 데이터프레임을 생성하는 함수입니다.\n",
    "def make_data(urllist, code):\n",
    "    text_list = []\n",
    "    for url in urllist:\n",
    "        article = Article(url, language='ko')\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        text_list.append(article.text)\n",
    "\n",
    "  #- 데이터프레임의 'news' 키 아래 파싱한 텍스트를 밸류로 붙여줍니다.\n",
    "    df = pd.DataFrame({'news': text_list})\n",
    "\n",
    "  #- 데이터프레임의 'code' 키 아래 한글 카테고리명을 붙여줍니다.\n",
    "    df['code'] = idx2word[str(code)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_list = [101,102, 103, 105]\n",
    "\n",
    "def make_total_data(page_num, code_list, date):\n",
    "    df = None\n",
    "\n",
    "    for code in code_list:\n",
    "        url_list = make_urllist(page_num, code, date)\n",
    "        df_temp = make_data(url_list, code)\n",
    "        print(str(code)+'번 코드에 대한 데이터를 만들었습니다.')\n",
    "\n",
    "    if df is not None:\n",
    "        df = pd.concat([df, df_temp])\n",
    "    else:\n",
    "        df = df_temp\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = make_total_data(1, code_list, 20200506)\n",
    "\n",
    "# csv_path = os.getenv(\"HOME\") + \"/aiffel/news_crawler/news_data.csv\"\n",
    "# df.to_csv(csv_path, index=False)\n",
    "\n",
    "# if os.path.exists(csv_path):\n",
    "#     print('{} File Saved!'.format(csv_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data (step.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17051, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LG전자는 14일 밤 온라인 행사를 통해 회전형 듀얼스크린이 적용된 하반기 전략폰 ...</td>\n",
       "      <td>경제</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[서울=뉴시스]이재준 기자 = 미국 뉴욕 증시는 14일 대형 인수합병(M&amp;A) 소식...</td>\n",
       "      <td>경제</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>신고리원전 3·4호기 전경. 부산일보DB\\n\\n더불어민주당 양이원영 국회의원은 14...</td>\n",
       "      <td>경제</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>사회적 약자를 위한 따뜻한 R＆D 로봇분야 대국민 아이디어 공모전 개최 안내. KE...</td>\n",
       "      <td>경제</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>경북 포항시가 잇따른 태풍으로 피해를 본 과수농가를 돕기 위해 대구경북능금농협과 함...</td>\n",
       "      <td>경제</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                news code\n",
       "0  LG전자는 14일 밤 온라인 행사를 통해 회전형 듀얼스크린이 적용된 하반기 전략폰 ...   경제\n",
       "1  [서울=뉴시스]이재준 기자 = 미국 뉴욕 증시는 14일 대형 인수합병(M&A) 소식...   경제\n",
       "2  신고리원전 3·4호기 전경. 부산일보DB\\n\\n더불어민주당 양이원영 국회의원은 14...   경제\n",
       "3  사회적 약자를 위한 따뜻한 R＆D 로봇분야 대국민 아이디어 공모전 개최 안내. KE...   경제\n",
       "4  경북 포항시가 잇따른 태풍으로 피해를 본 과수농가를 돕기 위해 대구경북능금농협과 함...   경제"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.getenv(\"HOME\") + \"/aiffel/news_crawler/\"\n",
    "df = pd.concat(map(pd.read_csv, glob.glob(os.path.join(path, \"*.csv\"))))\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing (step.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       전자는 일 밤 온라인 행사를 통해 회전형 듀얼스크린이 적용된 하반기 전략폰 윙을 공...\n",
       "1       서울뉴시스이재준 기자  미국 뉴욕 증시는 일 대형 인수합병 소식이 연달아 들어오면서...\n",
       "2       신고리원전 호기 전경 부산일보더불어민주당 양이원영 국회의원은 일 원자력발전소와 인근...\n",
       "3       사회적 약자를 위한 따뜻한  로봇분야 대국민 아이디어 공모전 개최 안내  제공한국산...\n",
       "4       경북 포항시가 잇따른 태풍으로 피해를 본 과수농가를 돕기 위해 대구경북능금농협과 함...\n",
       "                              ...                        \n",
       "1595    한국콘텐츠진흥원의 지능형 콘텐츠 창작도구 개발 과제 개요 한국콘텐츠진흥원의 지능형 ...\n",
       "1596    서울 강서구 마곡 사이언스파크 전경   제공 서울 강서구 마곡 사이언스파크 전경  ...\n",
       "1597    디지털데일리 이안나기자 대형 디스플레이와 부드러워진 펜이 소비자들에게 통한 것일까 ...\n",
       "1598    박영선 중기부 장관앞줄 왼쪽 세 번째이 일 서울 강남에서 열린 글로벌창업사관학교 강...\n",
       "1599    강덕영 한국유나이티드제약 대표한국유나이티드제약 제공 강덕영 한국유나이티드제약 대표한...\n",
       "Name: news, Length: 17051, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정규 표현식을 이용해서 한글 외의 문자는 전부 제거합니다.\n",
    "df['news'] = df['news'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "df['news']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "news    0\n",
      "code    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Null 값을 확인합니다.\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "뉴스 기사의 개수:  14105\n"
     ]
    }
   ],
   "source": [
    "# 중복된 데이터를 제거합니다.\n",
    "df.drop_duplicates(subset=['news'], inplace=True)\n",
    "print('뉴스 기사의 개수: ',len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 제거\n",
    "stopwords = ['에','는','은','을','했','에게','있','이','의','하','한','다','과','때문','할','수','무단','따른','및','금지','전재','경향신문','기자','는데','가','등','들','파이낸셜','저작','등','뉴스']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화 및 토큰화 과정에서 불용어 제거\n",
    "from konlpy.tag import Mecab\n",
    "tokenizer = Mecab()\n",
    "\n",
    "def preprocessing(data):\n",
    "    text_data = []\n",
    "\n",
    "    for sentence in data:\n",
    "        temp_data = []\n",
    "        #- 토큰화\n",
    "        temp_data = tokenizer.morphs(sentence) \n",
    "        #- 불용어 제거\n",
    "        temp_data = [word for word in temp_data if not word in stopwords] \n",
    "        text_data.append(temp_data)\n",
    "\n",
    "    text_data = list(map(' '.join, text_data))\n",
    "\n",
    "    return text_data\n",
    "\n",
    "text_data = preprocessing(df['news'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전자 일 밤 온라인 행사 를 통해 회전 형 듀얼 스크린 적용 된 하반기 전략 폰 윙 공개 사진 동영상 캡쳐 윙 스 위 블 회전 모드 에서 멀티 태 스 킹 사용 경험 제공 한다 내비게이션 화면 방해 받 지 않 고 전화 를 받 거나 동영상 시청 면서 웹 서핑 사진 전자 스마트폰 최초 로 짐벌 기능 탑재 고 기존 폰 에서 호평 받 았 던 동영상 촬영 기능 도 그대로 적용 해 동영상 콘텐츠 제작 최적 화 됐 다는 평가 사진 전자 데일리 장영 전자 이전 없 던 새로운 형태 스마트폰 고 나왔 회전 형 디스플레이 를 적용 하반기 전략 폰 윙 그 주인공 다일 밤 시 부터 시작 된 온라인 공개 행사 에서 실물 드러낸 윙 대해 소비자 사이 에서 우려 와 비판 도 지만 새로운 사용 성 혁신 성 대한 기대감 도 높 았 윙 존재 알려 지 면서 기대감 보다 논란 컸 던 제품 과거 삼성전자 애니콜 모델 중 하나 인 가로본능 폰 연상 시켜 구시대 적 라는 비판 내구 성 무게 중심 두께 대한 우려 컸 삼성전자 와 화웨이 경쟁사 폼 팩터 기기 형태 혁신 으로 폴 더블 접히 폰 택한 것 달리 듀얼 스크린 돌리 낯선 방식 택한 점 도 의구심 자아냈 다홍 신 태 전자 사업 본부 책임 고객 이미 익숙 해진 습관 바꾸 지 않 으면서 도 멀티 스크린 사용 방법 대해 고민 많이 다며 스 위 블 회전 형 듀얼 스크린 개발 배경 설명 메인 스크린 회전 시킨 상태 를 스 위 블 모드 라고 평상시 기존 바 형태 스마트폰 처럼 사용 다가 필요 때 만 스 위 블 모드 로 바꾸 면 된다는 것 특히 스 위 블 모드 에서 두 개 화면 이용 해 하나 어플리케이션 앱 사용 도 고 각 화면 다른 앱 띄울 도 어 사용 자 원 대로 직관 적 인 사용 가능 다는 것 장점 이날 온라인 행사 에서 유명 유 튜버 직접 윙 사용 경험 소개 며 멀티 태 스 킹 윙 만 강점 부각 시켰 유 튜버 영국 남자 메인 스크린 돌리 면 나타나 보조 스크린 정말 멋지 라며 예 를 어 아무런 방해 없이 전체 화면 으로 영상 시청 면서 동시 알림 확인 다고 말 또 다른 유 튜버 아찌 랜드 가격 비교 기 위해 여러 앱 왔 갔 필요 없 튜토리얼 영상 보 면서 받 지 않 고 전화 를 받 도 다면서 윙 이용 멀티 태 스팅 장점 구체 적 으로 었 세계 최초 로 스마트폰 적용 된 짐벌 기능 도 관심 끄 대목 짐벌 스마트폰 이나 카메라 으로 영상 촬영 때 카메라 흔들리 반대 방향 으로 움직임 만들 어 안정 적 고 부드러운 영상 촬영 가능 게 전문 장비 유 튜버 잭 킹 기존 짐벌 모든 장점 스마트폰 완벽 게 구현 다며 보통 흔들림 없 영상 위해 두 손 사용 지만 윙 손 으로 충분 다고 말 이어 컨트롤 툴 세컨드 스크린 어 편집 방해 받 지 않 는다고 덧붙였 한편 윙 어플리케이션 프로세서 로 스냅드래곤 를 탑재 스냅드래곤 퀄컴 지난해 말 출시 칩 섹 으로 퀄컴 최초 로 와 모뎀 통합 칩셋 고 성능 칩셋 지만 최신 프리미엄 급 사양 아니 어서 아쉽 다는 평가 장영 종합 경제 정보 미디어 데 일리 재 배포\n"
     ]
    }
   ],
   "source": [
    "text_data = preprocessing(df['news'])\n",
    "print(text_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA (step.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/theo/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 44221 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/theo/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 51228 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/theo/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 49373 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/theo/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 54876 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/theo/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 47928 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/theo/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 54868 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/theo/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 49324 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/theo/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 54924 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/theo/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 44284 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/theo/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 54617 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/theo/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 44221 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/theo/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 51228 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/theo/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 49373 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/theo/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 54876 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/theo/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 47928 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/theo/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 54868 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/theo/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 49324 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/theo/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 54924 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/theo/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 44284 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/theo/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 54617 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEKCAYAAAD+XoUoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAATrklEQVR4nO3dbYwd133f8e8v1ION2tVDtFUUkgjZhK0hF4hsbCUZLlBHQiRKDkKlcAwJrU24KpiiEmqjQRspL6rEjgAHaKLWgK2CqRjTQWpFcGyIcBgrrCwjcAs9rGJFFqWo2uohIiGJG1OW4xiRQfrfF/fQvlb2cu8uL+8ueb4f4GJn/nPm3jMXw98OZ87spKqQJPXhR1a7A5Kk6TH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6csZqd+B4Lrjggtq0adNqd0OSTimPPvroX1XVzGLL1nTob9q0ibm5udXuhiSdUpK8MGqZp3ckqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHVnTN2edDJtu+aPV7sJYnv/4e1e7C5JOQx7pS1JHDH1J6sjYoZ9kXZKvJflim9+c5KEk80n+IMlZrX52m59vyzcNvcetrf50kqsnvjWSpONazpH+h4GnhuZ/E7ijqn4KeBW4sdVvBF5t9TtaO5JcDFwPvB3YCnwqyboT674kaTnGCv0kG4D3Av+jzQe4Avhca7IbuK5Nb2vztOVXtvbbgLur6vWqeg6YBy6dwDZIksY07pH+fwX+E/C9Nv+jwDer6kibPwCsb9PrgRcB2vLXWvvv1xdZR5I0BUuGfpKfAw5V1aNT6A9JdiSZSzK3sLAwjY+UpG6Mc6T/buDnkzwP3M3gtM5/A85Ncmyc/wbgYJs+CGwEaMvPAb4xXF9kne+rqp1VNVtVszMziz74RZK0QkuGflXdWlUbqmoTgwuxX66qfwk8ALyvNdsO3Num97R52vIvV1W1+vVtdM9mYAvw8MS2RJK0pBO5I/dXgLuT/AbwNeCuVr8L+L0k88BhBr8oqKr9Se4BngSOADdV1dET+HxJ0jItK/Sr6ivAV9r0sywy+qaq/hb4xRHr3w7cvtxOSpImwztyJakjhr4kdcTQl6SOGPqS1BFDX5I60t1DVDRZPpRGOrV4pC9JHTH0Jakjhr4kdcTQl6SOGPqS1BFH70hriKOhdLJ5pC9JHTH0Jakjhr4kdcTQl6SOjPNg9DcleTjJnyfZn+TXW/3TSZ5L8lh7XdLqSfKJJPNJHk/yzqH32p7kmfbaPuIjJUknyTijd14Hrqiqbyc5E/hqkj9uy/5jVX3uDe2vYfD82y3AZcCdwGVJzgduA2aBAh5NsqeqXp3EhkiSljbOg9Grqr7dZs9srzrOKtuAz7T1HgTOTXIRcDWwr6oOt6DfB2w9se5LkpZjrHP6SdYleQw4xCC4H2qLbm+ncO5IcnarrQdeHFr9QKuNqkuSpmSs0K+qo1V1CbABuDTJPwFuBd4G/FPgfOBXJtGhJDuSzCWZW1hYmMRbSpKaZY3eqapvAg8AW6vqpXYK53Xgd4FLW7ODwMah1Ta02qj6Gz9jZ1XNVtXszMzMcronSVrCOKN3ZpKc26bfDPws8BftPD1JAlwHPNFW2QN8sI3iuRx4rapeAu4DrkpyXpLzgKtaTZI0JeOM3rkI2J1kHYNfEvdU1ReTfDnJDBDgMeDftvZ7gWuBeeA7wIcAqupwko8Bj7R2H62qwxPbEknSkpYM/ap6HHjHIvUrRrQv4KYRy3YBu5bZR0nShHhHriR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqyDh/T1+STjmbbvmj1e7CWJ7/+Hun+nke6UtSR8Z5XOKbkjyc5M+T7E/y662+OclDSeaT/EGSs1r97DY/35ZvGnqvW1v96SRXn7StkiQtapwj/deBK6rqp4FLgK3t2be/CdxRVT8FvArc2NrfCLza6ne0diS5GLgeeDuwFfhUewSjJGlKlgz9Gvh2mz2zvQq4Avhcq+9m8HB0gG1tnrb8yvbw9G3A3VX1elU9x+AZupdOYiMkSeMZ65x+knVJHgMOAfuA/wd8s6qOtCYHgPVtej3wIkBb/hrwo8P1RdaRJE3BWKFfVUer6hJgA4Oj87edrA4l2ZFkLsncwsLCyfoYSerSskbvVNU3gQeAdwHnJjk25HMDcLBNHwQ2ArTl5wDfGK4vss7wZ+ysqtmqmp2ZmVlO9yRJSxhn9M5MknPb9JuBnwWeYhD+72vNtgP3tuk9bZ62/MtVVa1+fRvdsxnYAjw8oe2QJI1hnJuzLgJ2t5E2PwLcU1VfTPIkcHeS3wC+BtzV2t8F/F6SeeAwgxE7VNX+JPcATwJHgJuq6uhkN0eSdDxLhn5VPQ68Y5H6sywy+qaq/hb4xRHvdTtw+/K7KUmaBO/IlaSOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1ZJzHJW5M8kCSJ5PsT/LhVv+1JAeTPNZe1w6tc2uS+SRPJ7l6qL611eaT3HJyNkmSNMo4j0s8AvxyVf1ZkrcCjybZ15bdUVX/ZbhxkosZPCLx7cCPA/8ryT9qiz/J4Bm7B4BHkuypqicnsSGSpKWN87jEl4CX2vRfJ3kKWH+cVbYBd1fV68Bz7Vm5xx6rON8es0iSu1tbQ1+SpmRZ5/STbGLwvNyHWunmJI8n2ZXkvFZbD7w4tNqBVhtVlyRNydihn+QtwB8CH6mqbwF3Aj8JXMLgfwK/NYkOJdmRZC7J3MLCwiTeUpLUjBX6Sc5kEPi/X1WfB6iqV6rqaFV9D/gdfnAK5yCwcWj1Da02qv5DqmpnVc1W1ezMzMxyt0eSdBzjjN4JcBfwVFX99lD9oqFmvwA80ab3ANcnOTvJZmAL8DDwCLAlyeYkZzG42LtnMpshSRrHOKN33g18APh6ksda7VeBG5JcAhTwPPBLAFW1P8k9DC7QHgFuqqqjAEluBu4D1gG7qmr/xLZEkrSkcUbvfBXIIov2Hmed24HbF6nvPd56kqSTyztyJakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdGedxiRuTPJDkyST7k3y41c9Psi/JM+3nea2eJJ9IMp/k8STvHHqv7a39M0m2n7zNkiQtZpwj/SPAL1fVxcDlwE1JLgZuAe6vqi3A/W0e4BoGz8XdAuwA7oTBLwngNuAyBg9Rv+3YLwpJ0nQsGfpV9VJV/Vmb/mvgKWA9sA3Y3ZrtBq5r09uAz9TAg8C57SHqVwP7qupwVb0K7AO2TnJjJEnHt6xz+kk2Ae8AHgIurKqX2qKXgQvb9HrgxaHVDrTaqLokaUrGDv0kbwH+EPhIVX1reFlVFVCT6FCSHUnmkswtLCxM4i0lSc1YoZ/kTAaB//tV9flWfqWdtqH9PNTqB4GNQ6tvaLVR9R9SVTuraraqZmdmZpazLZKkJYwzeifAXcBTVfXbQ4v2AMdG4GwH7h2qf7CN4rkceK2dBroPuCrJee0C7lWtJkmakjPGaPNu4APA15M81mq/CnwcuCfJjcALwPvbsr3AtcA88B3gQwBVdTjJx4BHWruPVtXhSWyEJGk8S4Z+VX0VyIjFVy7SvoCbRrzXLmDXcjooSZoc78iVpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHVknMcl7kpyKMkTQ7VfS3IwyWPtde3QsluTzCd5OsnVQ/WtrTaf5JbJb4okaSnjHOl/Gti6SP2OqrqkvfYCJLkYuB54e1vnU0nWJVkHfBK4BrgYuKG1lSRN0TiPS/zTJJvGfL9twN1V9TrwXJJ54NK2bL6qngVIcndr++TyuyxJWqkTOad/c5LH2+mf81ptPfDiUJsDrTaqLkmaopWG/p3ATwKXAC8BvzWpDiXZkWQuydzCwsKk3laSxApDv6peqaqjVfU94Hf4wSmcg8DGoaYbWm1UfbH33llVs1U1OzMzs5LuSZJGWFHoJ7loaPYXgGMje/YA1yc5O8lmYAvwMPAIsCXJ5iRnMbjYu2fl3ZYkrcSSF3KTfBZ4D3BBkgPAbcB7klwCFPA88EsAVbU/yT0MLtAeAW6qqqPtfW4G7gPWAbuqav+kN0aSdHzjjN65YZHyXcdpfztw+yL1vcDeZfVOkjRR3pErSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SerIkqGfZFeSQ0meGKqdn2Rfkmfaz/NaPUk+kWQ+yeNJ3jm0zvbW/pkk20/O5kiSjmecI/1PA1vfULsFuL+qtgD3t3mAaxg8F3cLsAO4Ewa/JBg8ZvEyBg9Rv+3YLwpJ0vQsGfpV9afA4TeUtwG72/Ru4Lqh+mdq4EHg3PYQ9auBfVV1uKpeBfbxd3+RSJJOspWe07+wql5q0y8DF7bp9cCLQ+0OtNqouiRpik74Qm5VFVAT6AsASXYkmUsyt7CwMKm3lSSx8tB/pZ22of081OoHgY1D7Ta02qj631FVO6tqtqpmZ2ZmVtg9SdJiVhr6e4BjI3C2A/cO1T/YRvFcDrzWTgPdB1yV5Lx2AfeqVpMkTdEZSzVI8lngPcAFSQ4wGIXzceCeJDcCLwDvb833AtcC88B3gA8BVNXhJB8DHmntPlpVb7w4LEk6yZYM/aq6YcSiKxdpW8BNI95nF7BrWb2TJE2Ud+RKUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSR04o9JM8n+TrSR5LMtdq5yfZl+SZ9vO8Vk+STySZT/J4kndOYgMkSeObxJH+z1TVJVU12+ZvAe6vqi3A/W0e4BpgS3vtAO6cwGdLkpbhZJze2QbsbtO7geuG6p+pgQeBc5NcdBI+X5I0womGfgF/kuTRJDta7cKqeqlNvwxc2KbXAy8OrXug1X5Ikh1J5pLMLSwsnGD3JEnDzjjB9f9ZVR1M8g+AfUn+YnhhVVWSWs4bVtVOYCfA7OzsstaVJB3fCR3pV9XB9vMQ8AXgUuCVY6dt2s9DrflBYOPQ6htaTZI0JSsO/SR/L8lbj00DVwFPAHuA7a3ZduDeNr0H+GAbxXM58NrQaSBJ0hScyOmdC4EvJDn2Pv+zqr6U5BHgniQ3Ai8A72/t9wLXAvPAd4APncBnS5JWYMWhX1XPAj+9SP0bwJWL1Au4aaWfJ0k6cd6RK0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqyNRDP8nWJE8nmU9yy7Q/X5J6NtXQT7IO+CRwDXAxcEOSi6fZB0nq2bSP9C8F5qvq2ar6LnA3sG3KfZCkbmXw6NopfVjyPmBrVf2bNv8B4LKqunmozQ5gR5v9x8DTU+vgyl0A/NVqd+I04vc5WX6fk3OqfJc/UVUziy1Y8YPRT5aq2gnsXO1+LEeSuaqaXe1+nC78PifL73NyTofvctqndw4CG4fmN7SaJGkKph36jwBbkmxOchZwPbBnyn2QpG5N9fROVR1JcjNwH7AO2FVV+6fZh5PklDoddQrw+5wsv8/JOeW/y6leyJUkrS7vyJWkjhj6ktQRQ1+SOmLoS1JH1tzNWaeKJP95iSaHquq/T6Uzp7gk/wd4EAjwxpEFATZW1fum3rFTlPvmZCX5AvDcqMXA2VX176bYpRNi6K/c5QzuM8iI5bsB/2GN5xtV9R9GLWz/6DQ+983JOuN02j8N/ZU7WlXfGrUwiWNhx7fUd+V3uTzum5N1Wu2fntNfudNqR9BpxX1TI3mkv3JnJvn7I5aFwR3HGs8/TPLvGX1O/9yp9+jU5r45WT+W5OdHLAvwlml25kR5R+4KJbmN0UdMAV7xYtl4kvwExz/6/G5VvTyt/pzq3DcnK8k/5/j7599U1aPT6s+J8kh/5S7Di2WT8lmWGL0DOHpnfO6bk/URBqN3Rn2fZwOGfge8WDY5jt6ZLPfNyTqtRu94IXflvFg2OX6Xk+X3OVmn1ffpkf7KebFMa5X7pkYy9FfuQQbn+kad5/vS9Lpyyjs2emcxjt5ZPvfNyXL0jjQpSd4FvAwcZXRIfbeqXpper6SBJD8ObGFwCmfU/vk3VTU3vV6dGENfqyrJnQxGm/xfBkegX3J4ptaKJHuB84GvMNg/v1pVR1a1UyfI0NeakORtwDXA1cA5wAMM/pH976o6upp9U9+SvAl4D4P9893AX/KDA5S/XMWurYihrzUnyZuBn2Hwj+xdVTW7yl2Svi/JZgb75lbgx6rq0lXu0rIY+lp1I/4U8PD5U+8g1apI8idVddVxlp9VVd+dZp9OlKN3tBb4p4C1Vs0cb+GpFvhg6Gtt8A5SrVXnJPkXoxZW1een2ZlJMPS1FpxWdzzqtHIO8HMs/r/QAgx9aQW8g1Rr1QtV9a9XuxOTZOhrLTh2B+liAvzx9Loi/ZBR15lOWYa+1gL/FLDWqn+12h2YNENfa4EXcrVWPThi/wtQVTXqtOSaZehrLfBCrtakqnrravdh0gx9rQVeyJWmxNDXWuCfApamxD/DIEkd8XGJktQRQ1+SOmLoS1JHDH1J6oihL0kd+f9PtLjZ9Sx4DwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 카테고리별 샘플 분포 확인\n",
    "df['code'].value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    code  count\n",
      "0  IT/과학   3121\n",
      "1     경제   4125\n",
      "2     사회   3678\n",
      "3  생활/문화   3797\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby('code').size().reset_index(name = 'count'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build NLP Classification Model (step.04)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련 데이터와 테스트 데이터를 분리 (step. 4-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(text_data, df['code'], random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련용 뉴스 기사의 개수 : 11040\n",
      "테스트용 뉴스 기사의 개수 :  3681\n",
      "훈련용 레이블의 개수 :  11040\n",
      "테스트용 레이블의 개수 :  3681\n"
     ]
    }
   ],
   "source": [
    "print('훈련용 뉴스 기사의 개수 :', len(X_train))\n",
    "print('테스트용 뉴스 기사의 개수 : ', len(X_test))\n",
    "print('훈련용 레이블의 개수 : ', len(y_train))\n",
    "print('테스트용 레이블의 개수 : ', len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF 벡터로 변환 (step. 4-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- 단어의 수를 카운트하는 사이킷런의 카운트벡터라이저입니다.\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "\n",
    "#- 카운트벡터라이저의 결과로부터 TF-IDF 결과를 얻습니다.\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "#- 나이브 베이즈 분류기를 수행합니다.\n",
    "#- X_train은 TF-IDF 벡터, y_train은 레이블입니다.\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "def tfidf_vectorizer(data):\n",
    "    data_counts = count_vect.transform(data)\n",
    "    data_tfidf = tfidf_transformer.transform(data_counts)\n",
    "    return data_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['경제']\n"
     ]
    }
   ],
   "source": [
    "new_sent = preprocessing([\"민주당 일각에서 법사위의 체계·자구 심사 기능을 없애야 한다는 \\\n",
    "                           주장이 나오는 데 대해 “체계·자구 심사가 법안 지연의 수단으로 \\\n",
    "                          쓰이는 것은 바람직하지 않다”면서도 “국회를 통과하는 법안 중 위헌\\\n",
    "                          법률이 1년에 10건 넘게 나온다. 그런데 체계·자구 심사까지 없애면 매우 위험하다”고 반박했다.\"])\n",
    "print(clf.predict(tfidf_vectorizer(new_sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       IT/과학       0.86      0.70      0.77       803\n",
      "          경제       0.65      0.81      0.72      1050\n",
      "          사회       0.74      0.79      0.76       916\n",
      "       생활/문화       0.80      0.65      0.72       912\n",
      "\n",
      "    accuracy                           0.74      3681\n",
      "   macro avg       0.76      0.74      0.74      3681\n",
      "weighted avg       0.75      0.74      0.74      3681\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(tfidf_vectorizer(X_test))\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build AUTO_NEWS_CRAWLER\n",
    "### (뉴스 데이터 크롤링 & 카테고리 자동 분류 & 모델별 정확도 구현)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 기능 정의\n",
    "1. 날짜와 분야를 입력하면 해당하는 뉴스를 크롤링하여 csv 파일로 저장\n",
    "2. 크롤링한 뉴스 데이터에서 한글 외 문자 삭제 기능 on/off\n",
    "3. 크롤링한 뉴스 데이터에서 중복 데이터 삭제 기능 on/off\n",
    "4. 불용어 대상 리스트 추가, 삭제 -> 클래스 개념 추가 공부하여 업데이트 필요\n",
    "5. 형태소 분류기 모델별 토큰화 -> .self 로 진행할 경우 커널이 죽는 현상 해결 필요\n",
    "6. 형태소 분류기 모델별 TF-IDF 벡터 변환 -> 형태소 분류 모델 추가 위해 자바 설치 필요\n",
    "7. 형태소 분류기 모델별 분석 보고서 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.display.max_rows=150\n",
    "%matplotlib inline\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# NLP\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "# crawling\n",
    "from konlpy.tag import Mecab\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from newspaper import Article\n",
    "\n",
    "# tokenizer\n",
    "from konlpy.tag import Hannanum\n",
    "from konlpy.tag import Mecab\n",
    "from konlpy.tag import Kkma\n",
    "from konlpy.tag import Komoran\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "\n",
    "class AUTONC:\n",
    "    \n",
    "    def __init__(self, drop_non_kor = 'off', drop_duplicates = 'off'):\n",
    "        \n",
    "        # 저장한 뉴스 데이터를 DataFrame 으로 가져옵니다.\n",
    "        path = os.getenv(\"HOME\") + \"/aiffel/news_crawler/\"\n",
    "        self.df = pd.concat(map(pd.read_csv, glob.glob(os.path.join(path, \"*.csv\"))))\n",
    "        \n",
    "        # 정규 표현식을 이용해서 한글 외의 문자는 전부 제거합니다.\n",
    "        # 해당 기능이 'on'이 된 경우에만 작동합니다.\n",
    "        if drop_non_kor == 'on':\n",
    "            self.df['news'] = self.df['news'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "            print('한글 외 문자 제거 완료: ', self.df['news'].head(), sep = '\\n')\n",
    "            \n",
    "        # 중복된 데이터를 제거합니다.\n",
    "        if drop_duplicates == 'on':         \n",
    "            self.df.drop_duplicates(subset=['news'], inplace=True)\n",
    "            print('중복 제거된 뉴스 기사의 개수:',len(self.df), sep = '\\n')\n",
    "                      \n",
    "            \n",
    "    def crawling(self, page_num = 1, code='경제', date = 20201123):\n",
    "        \n",
    "        # 날짜\n",
    "        self.date = date\n",
    "        \n",
    "        # 네이버 뉴스 페이지 코드\n",
    "        code_list = {\n",
    "            '정치':100,\n",
    "            '경제':101,\n",
    "            '사회':102,\n",
    "            '생활문화':103,\n",
    "            '세계': 104,\n",
    "            'IT과학':105\n",
    "                    }\n",
    "        self.code = code_list[code]\n",
    "        \n",
    "        # url 리스트 생성하기\n",
    "        urllist= []\n",
    "        for i in range(1, page_num + 1):\n",
    "            url = 'https://news.naver.com/main/list.nhn?mode=LSD&mid=sec&sid1='+str(self.code)+'&date='+str(self.date)+'&page='+str(i)\n",
    "            headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.90 Safari/537.36'}\n",
    "            news = requests.get(url, headers=headers)\n",
    "\n",
    "            # BeautifulSoup의 인스턴스 생성합니다. 파서는 html.parser를 사용합니다.\n",
    "            soup = BeautifulSoup(news.content, 'html.parser')\n",
    "\n",
    "            # CASE 1\n",
    "            news_list = soup.select('.newsflash_body .type06_headline li dl')\n",
    "            # CASE 2\n",
    "            news_list.extend(soup.select('.newsflash_body .type06 li dl'))\n",
    "        \n",
    "        # 각 뉴스로부터 a 태그인 <a href ='주소'> 에서 '주소'만을 가져옵니다.\n",
    "        for line in news_list:\n",
    "            urllist.append(line.a.get('href'))\n",
    "            \n",
    "        # url 리스트에서 뉴스 텍스트 가져오기\n",
    "        text_list = []\n",
    "        for url in urllist:\n",
    "            article = Article(url, language='ko')\n",
    "            article.download()\n",
    "            article.parse()\n",
    "            text_list.append(article.text)\n",
    "        \n",
    "        idx2word = {'100' : '정치' ,'101' : '경제', '102' : '사회', '103' : '생활/문화', '104' : '세계','105' : 'IT/과학'}\n",
    "        \n",
    "        data = pd.DataFrame({'news': text_list})\n",
    "        data['code'] = idx2word[str(self.code)]\n",
    "        \n",
    "        csv_path = os.getenv(\"HOME\") + \"/aiffel/news_crawler/\" + str(self.date) + '_' +str(self.code) + '_news_data.csv'\n",
    "        data.to_csv(csv_path, index=False)\n",
    "\n",
    "        if os.path.exists(csv_path):\n",
    "            print('{} File Saved!'.format(csv_path))\n",
    "    \n",
    "\n",
    "           \n",
    "    def fit(self):\n",
    "        \n",
    "        # tokenizer 함수에서 저장한 text data를 전역변수로 설정합니다.\n",
    "        global text_data\n",
    "        self.text_data = text_data\n",
    "        \n",
    "        # train, test data 분류\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.text_data, self.df['code'], \n",
    "                                                                                test_size=0.3, \n",
    "                                                                                random_state = 91)\n",
    "        #TF-IDF 벡터로 변환\n",
    "        #- 단어의 수를 카운트하는 사이킷런의 카운트벡터라이저입니다.\n",
    "        count_vect = CountVectorizer()\n",
    "        self.X_train_counts = count_vect.fit_transform(self.X_train)\n",
    "\n",
    "        #- 카운트벡터라이저의 결과로부터 TF-IDF 결과를 얻습니다.\n",
    "        tfidf_transformer = TfidfTransformer()\n",
    "        self.X_train_tfidf = tfidf_transformer.fit_transform(self.X_train_counts)\n",
    "\n",
    "        #- 나이브 베이즈 분류기를 수행합니다.\n",
    "        #- X_train은 TF-IDF 벡터, y_train은 레이블입니다.\n",
    "        self.clf = MultinomialNB().fit(self.X_train_tfidf, self.y_train)\n",
    "        \n",
    "        self.data_tfidf = tfidf_transformer.transform(count_vect.transform(self.X_test))\n",
    "        \n",
    "          \n",
    "    def predict(self):\n",
    "        y_pred = self.clf.predict(self.data_tfidf)\n",
    "        self.results = {\n",
    "                'accuracy_score': accuracy_score(self.y_test, y_pred),\n",
    "                'classification_report': classification_report(self.y_test, y_pred),\n",
    "                'confusion_matrix': confusion_matrix(self.y_test, y_pred)\n",
    "            }          \n",
    "\n",
    "    def show(self, insight='classification_report'):\n",
    "        \n",
    "        if insight == 'confusion_matrix':\n",
    "            sns.heatmap(self.results[insight], annot=True)\n",
    "            plt.show()\n",
    "\n",
    "        else:\n",
    "            print(self.results[insight])            \n",
    "            \n",
    "    def print_df(self):\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['에','는','은','을','했','에게','있','이','의','하','한','다','과','때문','할','수','무단','따른','및','금지','전재','경향신문','기자','는데','가','등','들','파이낸셜','저작','등','뉴스']\n",
    "\n",
    "\n",
    "def tokenizer(data, name = 'Mecab'):\n",
    "    \n",
    "         # 토큰화 모델\n",
    "    models = {\n",
    "        'Mecab': Mecab,\n",
    "        'Okt': Okt,\n",
    "        'Hannanum': Hannanum,\n",
    "        'Kkma': Kkma,\n",
    "        'Komoran': Komoran\n",
    "    }\n",
    "    \n",
    "    tokenizer = models[name]()\n",
    "    \n",
    "    text_data = []\n",
    "\n",
    "    for sentence in data:\n",
    "        temp_data = []\n",
    "        #- 토큰화\n",
    "        temp_data = tokenizer.morphs(sentence) \n",
    "        #- 불용어 제거\n",
    "        temp_data = [word for word in temp_data if not word in stopwords] \n",
    "        text_data.append(temp_data)\n",
    "\n",
    "    text_data = list(map(' '.join, text_data))\n",
    "\n",
    "    return text_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한글 외 문자 제거 완료: \n",
      "0    전자는 일 밤 온라인 행사를 통해 회전형 듀얼스크린이 적용된 하반기 전략폰 윙을 공...\n",
      "1    서울뉴시스이재준 기자  미국 뉴욕 증시는 일 대형 인수합병 소식이 연달아 들어오면서...\n",
      "2    신고리원전 호기 전경 부산일보더불어민주당 양이원영 국회의원은 일 원자력발전소와 인근...\n",
      "3    사회적 약자를 위한 따뜻한  로봇분야 대국민 아이디어 공모전 개최 안내  제공한국산...\n",
      "4    경북 포항시가 잇따른 태풍으로 피해를 본 과수농가를 돕기 위해 대구경북능금농협과 함...\n",
      "Name: news, dtype: object\n",
      "중복 제거된 뉴스 기사의 개수:\n",
      "14094\n"
     ]
    }
   ],
   "source": [
    "auto = AUTONC(drop_non_kor = 'on', drop_duplicates = 'on')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화 & 불용어 제거\n",
    "text_data = tokenizer(auto.print_df()['news'], name = 'Okt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 & 분류\n",
    "auto.fit()\n",
    "auto.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류 결과 확인\n",
    "auto.show(insight='confusion_matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.show(insight = 'classification_report')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추가로 뉴스 기사를 더 모아봅시다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/theo/aiffel/news_crawler/20201120_100_news_data.csv File Saved!\n"
     ]
    }
   ],
   "source": [
    "auto.crawling(code='정치', date = 20201120)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
